{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Module 4 Assessment</h1>\n",
    "\n",
    "## Overview\n",
    "\n",
    "This assessment is designed to test your understanding of the Mod 4 material. It covers:\n",
    "\n",
    "* Calculus, Cost Function, and Gradient Descent\n",
    "* Extensions to Linear Models\n",
    "* Introduction to Linear Regression\n",
    "* Working with Time Series Data\n",
    "\n",
    "\n",
    "Read the instructions carefully. You will be asked both to write code and respond to a few short answer questions.\n",
    "\n",
    "### Note on the short answer questions\n",
    "\n",
    "For the short answer questions please use your own words. The expectation is that you have not copied and pasted from an external source, even if you consult another source to help craft your response. While the short answer questions are not necessarily being assessed on grammatical correctness or sentence structure, do your best to communicate yourself clearly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Calculus, Cost Function, and Gradient Descent\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![best fit line](visuals/best_fit_line.png)\n",
    "\n",
    "The best fit line that goes through the scatterplot up above can be generalized in the following equation: $$y = mx + b$$\n",
    "\n",
    "Of all the possible lines, we can prove why that particular line was chosen using the plot down below:\n",
    "\n",
    "![](visuals/cost_curve.png)\n",
    "\n",
    "where RSS is defined as the residual sum of squares:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "RSS &= \\sum_{i=1}^n(actual - expected)^2 \\\\\n",
    "&= \\sum_{i=1}^n(y_i - \\hat{y})^2 \\\\\n",
    "&= \\sum_{i=1}^n(y_i - (mx_i + b))^2\n",
    "\\end{align}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What is a more generalized name for the RSS curve above? How is it related to machine learning models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// your answer here //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Would you rather choose a $m$ value of 0.08 or 0.03 from the curve up above? In your answer, also explain what it means to move along the curve in relation to the best fit line with respect to $m$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// your answer here //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](visuals/gd.png)\n",
    "\n",
    "### 3. Using the gradient descent visual from above, explain why the distance between each step is getting smaller as more steps occur with gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// your answer here //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the purpose of a learning rate in gradient descent? Explain how a very small and a very large learning rate would affect the gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// your answer here //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Extensions to Linear Regression\n",
    "---\n",
    "\n",
    "In this section, you're going to be creating linear models that are more complicated than a simple linear regression. In the cells below, we are importing relevant modules that you might need later on. We also load and prepare the dataset for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, roc_curve, roc_auc_score, accuracy_score\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('raw_data/advertising.csv').drop('Unnamed: 0',axis=1)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('sales', axis=1)\n",
    "y = data['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into training and testing set. Do not change the random state please!\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y,random_state=2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. We'd like to add a bit of complexity to the model created in the example above, and we will do it by adding some polynomial terms. Write a Function to calculate train and test error for different polynomial degrees ranging from (1-10).\n",
    "\n",
    "This function should:\n",
    "* take `poly_degree` as a parameter that will be used to create all different possible polynomial degrees starting at 1 UP TO and including poly_degree\n",
    "* create a PolynomialFeatures object for each degree and fit a linear regression model using the transformed data\n",
    "* calculate the root mean square error for each level of polynomial\n",
    "* return two lists that contain the `train_errors` and `test_errors` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_degree(poly_degree):\n",
    "    \"\"\"Calculate train and test error for different polynomial degree (1-10)\"\"\"\n",
    "    train_error_list = []\n",
    "    test_error_list = []\n",
    "    # // your code here //\n",
    "    return train_error_list, test_error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_train, error_test = calc_degree(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#error_train = [1.633049529710119,\n",
    " 0.6544219763525787,\n",
    " 0.4923003895833528,\n",
    " 0.42636966692892925,\n",
    " 0.2552375092236587,\n",
    " 0.21455738787043777,\n",
    " 0.17677574592197967,\n",
    " 0.20526596216126342,\n",
    " 0.26914830727034605,\n",
    " 0.28892220322372025]\n",
    "#error_test = [1.8399932733741966,\n",
    " 0.4317931087085349,\n",
    " 0.39091400558118194,\n",
    " 1.3972328447228304,\n",
    " 2.381671115675543,\n",
    " 4.672887984282909,\n",
    " 5.391079429485139,\n",
    " 88.12110401687424,\n",
    " 24002.511402029148,\n",
    " 177660.21087344288]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. What is the optimal number of degrees for our polynomial features in this model? In general, how does increasing the polynomial degree relate to the Bias/Variance tradeoff? \n",
    "\n",
    "<img src =\"visuals/rsme_poly_2.png\" width = \"600\">\n",
    "\n",
    "<!---\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "degree = list(range(1, 10 + 1))\n",
    "ax.plot(degree, error_train[0:len(degree)], \"-\", label=\"Train Error\")\n",
    "ax.plot(degree, error_test[0:len(degree)], \"-\", label=\"Test Error\")\n",
    "ax.set_yscale(\"log\")\n",
    "ax.set_xlabel(\"Polynomial Feature Degree\")\n",
    "ax.set_ylabel(\"Root Mean Squared Error\")\n",
    "ax.legend()\n",
    "ax.set_title(\"Relationship Between Degree and Error\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"visuals/rsme_poly.png\",\n",
    "            dpi=150,\n",
    "            bbox_inches=\"tight\")\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// your answer here //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. In general what methods would you can use to reduce overfitting and underfitting? Provide an example for both and explain how each technique works to reduce the problems of underfitting and overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// your answer here //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create the function `train_regularizer` below to train a regularized model and obtain the the testing error. You can use a regularization technique of your choosing.\n",
    "\n",
    "We've taken care to load the polynomial transformed data for you, held in X_poly_train and X_poly_test. \n",
    "\n",
    "The function should:\n",
    "* take in X_train, X_test, y_train, y_test as parameters. We are assuming that the data has already been transformed into a polynomial ^ 10\n",
    "* return the root mean square error of the predictions for the test data\n",
    "> Hint: Make sure to include all necessary preprocessing steps required when fitting a regularized model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "poly = PolynomialFeatures(degree=10, interaction_only=False, include_bias=False)\n",
    "X_poly_train = poly.fit_transform(X_train) \n",
    "X_poly_test = poly.transform(X_test)\n",
    "pickle.dump(X_poly_train, open(\"write_data/poly_train_model.pkl\", \"wb\"))\n",
    "pickle.dump(X_poly_test, open(\"write_data/poly_test_model.pkl\", \"wb\"))\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly_train = pickle.load(open(\"write_data/poly_train_model.pkl\", \"rb\"))\n",
    "X_poly_test = pickle.load(open(\"write_data/poly_test_model.pkl\", \"rb\"))\n",
    "\n",
    "def train_regularizer(X_train, X_test, y_train, y_test):\n",
    "    # // your code here //\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Introduction to Logistic Regression\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "# load data\n",
    "ads_df = pd.read_csv(\"raw_data/social_network_ads.csv\")\n",
    "\n",
    "# one hot encode categorical feature\n",
    "def is_female(x):\n",
    "    \"\"\"Returns 1 if Female; else 0\"\"\"\n",
    "    if x == \"Female\":\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "ads_df[\"Female\"] = ads_df[\"Gender\"].apply(is_female)\n",
    "ads_df.drop([\"User ID\", \"Gender\"], axis=1, inplace=True)\n",
    "ads_df.head()\n",
    "\n",
    "# separate features and target\n",
    "X = ads_df.drop(\"Purchased\", axis=1)\n",
    "y = ads_df[\"Purchased\"]\n",
    "\n",
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=19)\n",
    "\n",
    "# preprocessing\n",
    "scale = StandardScaler()\n",
    "scale.fit(X_train)\n",
    "X_train = scale.transform(X_train)\n",
    "X_test = scale.transform(X_test)\n",
    "\n",
    "# save preprocessed train/test split objects\n",
    "pickle.dump(X_train, open(\"write_data/social_network_ads/X_train_scaled.pkl\", \"wb\"))\n",
    "pickle.dump(X_test, open(\"write_data/social_network_ads/X_test_scaled.pkl\", \"wb\"))\n",
    "pickle.dump(y_train, open(\"write_data/social_network_ads/y_train.pkl\", \"wb\"))\n",
    "pickle.dump(y_test, open(\"write_data/social_network_ads/y_test.pkl\", \"wb\"))\n",
    "\n",
    "# build model\n",
    "model = LogisticRegression(C=1e5, solver=\"lbfgs\")\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# create confusion matrix\n",
    "# tn, fp, fn, tp\n",
    "cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "cnf_matrix\n",
    "\n",
    "# build confusion matrix plot\n",
    "plt.imshow(cnf_matrix,  cmap=plt.cm.Blues) #Create the basic matrix.\n",
    "\n",
    "# Add title and Axis Labels\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "# Add appropriate Axis Scales\n",
    "class_names = set(y_test) #Get class labels to add to matrix\n",
    "tick_marks = np.arange(len(class_names))\n",
    "plt.xticks(tick_marks, class_names)\n",
    "plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Add Labels to Each Cell\n",
    "thresh = cnf_matrix.max() / 2. #Used for text coloring below\n",
    "#Here we iterate through the confusion matrix and append labels to our visualization.\n",
    "for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "        plt.text(j, i, cnf_matrix[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cnf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "# Add a Side Bar Legend Showing Colors\n",
    "plt.colorbar()\n",
    "\n",
    "# Add padding\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visuals/cnf_matrix.png\",\n",
    "            dpi=150,\n",
    "            bbox_inches=\"tight\")\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cnf matrix](visuals/cnf_matrix.png)\n",
    "\n",
    "### 1. Using the confusion matrix up above, calculate precision, recall, and F-1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // your code here //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.  What is a real life example of when you would care more about recall than precision? Make sure to include information about errors in your explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// your answer here //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "# save preprocessed train/test split objects\n",
    "X_train = pickle.load(open(\"write_data/social_network_ads/X_train_scaled.pkl\", \"rb\"))\n",
    "X_test = pickle.load(open(\"write_data/social_network_ads/X_test_scaled.pkl\", \"rb\"))\n",
    "y_train = pickle.load(open(\"write_data/social_network_ads/y_train.pkl\", \"rb\"))\n",
    "y_test = pickle.load(open(\"write_data/social_network_ads/y_test.pkl\", \"rb\"))\n",
    "\n",
    "# build model\n",
    "model = LogisticRegression(C=1e5, solver=\"lbfgs\")\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "labels = [\"Age\", \"Estimated Salary\", \"Female\", \"All Features\"]\n",
    "colors = sns.color_palette(\"Set2\")\n",
    "plt.figure(figsize=(10, 8))\n",
    "# add one ROC curve per feature\n",
    "for feature in range(3):\n",
    "    # female feature is one hot encoded so it produces an ROC point rather than a curve\n",
    "    # for this reason, female will not be included in the plot at all since it is\n",
    "    # disingeneuous to call it a curve.\n",
    "    if feature == 2:\n",
    "        pass\n",
    "    else:\n",
    "        X_train_feat = X_train[:, feature].reshape(-1, 1)\n",
    "        X_test_feat = X_test[:, feature].reshape(-1, 1)\n",
    "        logreg = LogisticRegression(fit_intercept=False, C=1e12, solver='lbfgs')\n",
    "        model_log = logreg.fit(X_train_feat, y_train)\n",
    "        y_score = model_log.decision_function(X_test_feat)\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "        lw = 2\n",
    "        plt.plot(fpr, tpr, color=colors[feature],\n",
    "                 lw=lw, label=labels[feature])\n",
    "\n",
    "# add one ROC curve with all the features\n",
    "model_log = logreg.fit(X_train, y_train)\n",
    "y_score = model_log.decision_function(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color=colors[3], lw=lw, label=labels[3])\n",
    "\n",
    "# create foundation of the plot\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i / 20.0 for i in range(21)])\n",
    "plt.xticks([i / 20.0 for i in range(21)])\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"visuals/many_roc.png\",\n",
    "            dpi=150,\n",
    "            bbox_inches=\"tight\")\n",
    "--->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pick the best ROC curve from this graph and explain your choice. \n",
    "\n",
    "*Note: each ROC curve represents one model, each labeled with the feature(s) inside each model*.\n",
    "\n",
    "<img src = \"visuals/many_roc.png\" width = \"700\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// your answer here //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!---\n",
    "# sorting by 'Purchased' and then dropping the last 130 records\n",
    "dropped_df = ads_df.sort_values(by=\"Purchased\")[:-130]\n",
    "dropped_df.reset_index(inplace=True)\n",
    "pickle.dump(dropped_df, open(\"write_data/sample_network_data.pkl\", \"wb\"))\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df = pickle.load(open(\"write_data/sample_network_data.pkl\", \"rb\"))\n",
    "\n",
    "# partion features and target \n",
    "X = network_df.drop(\"Purchased\", axis=1)\n",
    "y = network_df[\"Purchased\"]\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=2019)\n",
    "\n",
    "# scale features\n",
    "scale = StandardScaler()\n",
    "scale.fit(X_train)\n",
    "X_train = scale.transform(X_train)\n",
    "X_test = scale.transform(X_test)\n",
    "\n",
    "# build classifier\n",
    "model = LogisticRegression(C=1e5, solver=\"lbfgs\")\n",
    "model.fit(X_train,y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# get the accuracy score\n",
    "print(f\"The original classifier has an accuracy score of {round(accuracy_score(y_test, y_test_pred), 3)}.\")\n",
    "\n",
    "# get the area under the curve from an ROC curve\n",
    "y_score = model.decision_function(X_test)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "auc = round(roc_auc_score(y_test, y_score), 3)\n",
    "print(f\"The original classifier has an area under the ROC curve of {auc}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. The model above has an accuracy score that might be too good to believe. Using `y.value_counts()`, explain how `y` is affecting the accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// your answer here //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Update the inputs in the classification model using a technique to address the issues mentioned up above in question 4. Make sure to use a Logistic Regression model as your classifier.\n",
    "\n",
    "Be sure to include updates regarding:\n",
    "* the accuracy score; and\n",
    "* the area under the curve (AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // your code here //\n",
    "\n",
    "# print accuracy\n",
    "score_update = None\n",
    "print(f\"The updated classifier has an accuracy score of {score_update}.\")\n",
    "\n",
    "# print auc\n",
    "auc_update = None\n",
    "print(f\"The updated classifier has an area under the ROC curve of {auc_update}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Time Series\n",
    "---\n",
    "\n",
    "<!---Create stock_df and save as .pkl\n",
    "stocks_df = pd.read_csv(\"raw_data/all_stocks_5yr.csv\")\n",
    "stocks_df[\"clean_date\"] = pd.to_datetime(stocks_df[\"date\"], format=\"%Y-%m-%d\")\n",
    "stocks_df.drop([\"date\", \"clean_date\", \"volume\", \"Name\"], axis=1, inplace=True)\n",
    "stocks_df.rename(columns={\"string_date\": \"date\"}, inplace=True)\n",
    "pickle.dump(stocks_df, open(\"write_data/all_stocks_5yr.pkl\", \"wb\"))\n",
    "--->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df = pickle.load(open(\"write_data/all_stocks_5yr.pkl\", \"rb\"))\n",
    "stocks_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Transform the `date` feature so that it becomes a `datetime` object that contains the following format: YYYY-MM-DD and set `date` to be the index of `stocks_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // your code here //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Perform monthly upsampling on `stocks_df` that takes the mean of the `open`, `high`, `low`, and `close` features on a monthly basis. Store the results in `stocks_monthly_df`.\n",
    "\n",
    "> Hint: `stocks_monthly_df` should have 61 rows and 4 columns after you perform upsampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // your code here //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a line graph that visualizes the monthly open stock prices from `stocks_monthly_df` for the purposes of identifying if average monthly open stock price is stationary or not using the rolling mean and rolling standard deviation.\n",
    "\n",
    "> Hint: \n",
    "> * store your sliced version of `stocks_monthly_df` in a new DataFrame called `open_monthly_df`;\n",
    "> * use a window size of 3 to represent one quarter of time in a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // your code here //\n",
    "\n",
    "open_monthly_df = None\n",
    "\n",
    "rolmean = None\n",
    "rolstd = None\n",
    "\n",
    "# note: do not rename the objects otherwise the plot code will not work\n",
    "fig, ax = plt.subplots(figsize=(13, 10))\n",
    "ax.plot(open_monthly_df, color=\"blue\",label=\"Average monthly opening stock price\")\n",
    "ax.plot(rolmean, color=\"red\", label=\"Rolling quarterly mean\")\n",
    "ax.plot(rolstd, color=\"black\", label=\"Rolling quarterly std. deviation\")\n",
    "ax.set_ylim(0, 120)\n",
    "ax.legend()\n",
    "fig.suptitle(\"Average monthly open stock prices, Feb. 2013 to Feb. 2018\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// your answer here //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use the Dickey-Fuller Test to identify if `open_monthly_df` is stationary. Does this confirm your answer from Question 3? Explain why the time series is stationary or not based on the output from the Dickey-Fuller Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# // your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// your answer here //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Looking at the decomposition of the time series in `open_monthly_df`, it looks like the peaks are the same value. To confirm or deny this, create a function that returns a dictionary where each key is year and each values is the maximum value from the `seasonal` object for each year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "decomposition = seasonal_decompose(np.log(open_monthly_df))\n",
    "\n",
    "# Gather the trend, seasonality and noise of decomposed object\n",
    "seasonal = decomposition.seasonal\n",
    "\n",
    "# Plot gathered statistics\n",
    "plt.figure(figsize=(13, 10))\n",
    "plt.plot(seasonal,label='Seasonality', color=\"blue\")\n",
    "plt.title(\"Seasonality of average monthly open stock prices, Feb. 2013 to Feb. 2018\")\n",
    "plt.ylabel(\"Average monthly open stock prices\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_yearly_max(seasonal_series):\n",
    "    \"\"\"Returns the max seasonal value for each year\"\"\"\n",
    "    # // your code here //\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_yearly_max(seasonal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
